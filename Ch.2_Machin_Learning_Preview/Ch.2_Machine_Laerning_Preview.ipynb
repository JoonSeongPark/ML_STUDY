{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p style=\"text-align: right; font-weight: bold; font-size: 50px\"> Chapter. 2</p>\n",
    "<p style=\"text-align: right; font-weight: bold; font-size: 25px\"> : Machine Learning Preview</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button type=\"button\" style=\"float: right;\"> 13기 디자인팀 박준성 </button>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Open Dataset\n",
    "- [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/)  \n",
    "- [Kaggle Dataset](http://www.kaggle.com/datasets)  \n",
    "- [Amazon AWS Dataset](http://aws.amazon.com/ko/datasets)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing Project\n",
    "## Machine Learning System\n",
    "1. <b>Supervised Laerning</b><s style=\"font-size:8px;\">(회귀, 분류)</s> / <b>Unsupervised Learning</b> / <b>Reinforcement Learning</b> 중에 맞는 것을 선택한다.  \n",
    "2. 모델에 사용될 Feature의 종류와 수를 확인한다.  \n",
    "3. 데이터의 수와 상태에 따라, <b>'Batch Learning'</b>과 <b>'Online Learning'</b>을 정한다.\n",
    "    - <b>Batch Learning:</b> 데이터 전체를 한 번에 학습.\n",
    "    - <b>Online Learning:</b> 데이터를 순차적으로 mini-batch를 통해서 학습.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfomance Measure\n",
    "<p style=\"text-align: right;\">(출처: [Machine Learning Mastery](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/))  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Classification Accuracy\n",
    ": 모든 예측 중에서 올바른 예측의 비율  \n",
    "Classification에 있어서 가장 기본적은 metric으로 각 클래스의 개수가 같고, Prediction과 Prediction Errors가 동등하게 중요할 경우에만 사용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7695 \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names = names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = model_selection.KFold(n_splits=10, random_state = 0)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv = kfold, scoring = 'accuracy')\n",
    "print(\"Accuracy: %.4f \" %results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Log Loss\n",
    ": 확률값을 Prediction Input으로 받는 metric으로 0에 가까울수록 좋다.  \n",
    "따라서, (-)를 곱한Negative Log Loss를 사용함으로 직관적으로 클수록 좋다로 판단.\n",
    "<p style = \"text-align: center; font-size: 17px;\">${Log Loss} = {-(y\\log(p) + (1-y)\\log(1-p))}$  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: -0.4927\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names = names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "kfold = model_selection.KFold(n_splits=10, random_state = 0)\n",
    "model = LogisticRegression()\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(\"Log Loss: %.4f\" %results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 AUC (Area Under ROC Curve)\n",
    "* <b>ROC Curve:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
